[{"authors":["admin"],"categories":null,"content":" I am a Senior Research Scientist at Google Research where I work on developing methods for improving the robustness, reliability, and efficiency of Machine Learning models. Specifically, I develop reliable uncertainty estimates for practical applications. For example, to control and improve adaptive computation capabilities, or to derive small and accurate prediction sets. Currently, I am mainly working on Natural Language Processing applications, focusing on improving the precision of information-related tasks. For example, improving the robustness of Fact Verification and Language Inference systems, and leveraging them for solving related classification and generation tasks.  I have also worked on Deep Learning for Computer Vision, Medical applications, Computational Chemistry, as well as other topics in NLP including static and contextual Word Embeddings, Large Language Models, Transfer Learning, Cross-Lingual, Question Answering, program synthesis, and more. Many of my projects have been featured in global media. I've completed my Ph.D. at MIT CSAIL, advised by Prof. Regina Barzilay, and was a member of the NLP and Learn To Cure groups. Before coming to MIT, I completed my MSc at Tel-Aviv University, advised by Prof. Lior Wolf. ","date":1673740800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1673740800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://talschuster.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Senior Research Scientist at Google Research where I work on developing methods for improving the robustness, reliability, and efficiency of Machine Learning models. Specifically, I develop reliable uncertainty estimates for practical applications.","tags":null,"title":"Tal Schuster","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://talschuster.github.io/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Yi Tay","Mostafa Dehghani","Vinh Q Tran","Xavier Garcia","Jason Wei","Xuezhi Wang","Hyung Won Chung","Siamak Shakeri","Dara Bahri","Tal Schuster","Huaixiu Steven Zheng","Denny Zhou","Neil Houlsby","Donald Metzler"],"categories":null,"content":"","date":1673740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673740800,"objectID":"8a73f675c10f8fffd07af38f088bc9b5","permalink":"https://talschuster.github.io/publication/ul2/","publishdate":"2023-01-15T00:00:00Z","relpermalink":"/publication/ul2/","section":"publication","summary":"Existing pre-trained models are generally geared towards a particular class of problems. To date, there seems to be still no consensus on what the right architecture and pre-training setup should be. This paper presents a unified framework for pre-training models that are universally effective across datasets and setups. We begin by disentangling architectural archetypes with pre-training objectives -- two concepts that are commonly conflated. Next, we present a generalized \u0026 unified perspective for self-supervision in NLP and show how different pre-training objectives can be cast as one another and how interpolating between different objectives can be effective. We then propose Mixture-of-Denoisers (MoD), a pre-training objective that combines diverse pre-training paradigms together. We furthermore introduce a notion of mode switching, wherein downstream fine-tuning is associated with specific pre-training schemes. We conduct extensive ablative experiments to compare multiple pre-training objectives and find that our method pushes the Pareto-frontier by outperforming T5 \u0026 GPT-like models across multiple diverse setups. By scaling our model up to 20B parameters, we achieve SOTA performance on 50 well-established supervised finetuning based NLP tasks. Our model also achieve strong results at in-context learning, outperforming 175B GPT-3 on zero-shot SuperGLUE and tripling the performance of T5-XXL on one-shot summarization. On 0-shot MMLU, UL2 20B outperforms T0 and T5 models. UL2 20B also works well with chain-of-thought prompting and reasoning, making it an appealing choice for research into reasoning at a small to medium scale of 20B parameters. Finally, we apply FLAN instruction tuning to the UL2 20B model, achieving MMLU and Big-Bench scores competitive to FLAN-PaLM 62B. We release Flax-based T5X checkpoints for the UL2 20B \u0026 Flan-UL2 20B.","tags":[""],"title":"UL2: Unifying Language Learning Paradigms","type":"publication"},{"authors":["Tal Schuster","Adam Fisch","Jai Gupta","Mostafa Dehghani","Dara Bahri","Vinh Q. Tran","Yi Tay","Donald Metzler"],"categories":null,"content":"News coverage:\n Synced  MarkTechPost  Search Engine Journal   ","date":1670630400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670630400,"objectID":"e5a2477d2e95138b039dbcf0445be4bc","permalink":"https://talschuster.github.io/publication/calm/","publishdate":"2022-12-10T00:00:00Z","relpermalink":"/publication/calm/","section":"publication","summary":"Recent advances in Transformer-based large language models (LLMs) have led to significant performance improvements across many tasks. These gains come with a drastic increase in the models' size, potentially leading to slow and costly use at inference time. In practice, however, the series of generations made by LLMs is composed of varying levels of difficulty. While certain predictions truly benefit from the models' full capacity, other continuations are more trivial and can be solved with reduced compute. In this work, we introduce Confident Adaptive Language Modeling (CALM), a framework for dynamically allocating different amounts of compute per input and generation timestep. Early exit decoding involves several challenges that we address here, such as: (1) what confidence measure to use; (2) connecting sequence-level constraints to local per-token exit decisions; and (3) attending back to missing hidden representations due to early exits in previous tokens. Through theoretical analysis and empirical experiments on three diverse text generation tasks, we demonstrate the efficacy of our framework in reducing compute -- potential speedup of up to ×3 -- while provably maintaining high performance.","tags":[""],"title":"Confident Adaptive Language Modeling","type":"publication"},{"authors":["Yi Tay","Vinh Q Tran","Mostafa Dehghani","Jianmo Ni","Dara Bahri","Harsh Mehta","Zhen Qin","Kai Hui","Zhe Zhao","Jai Gupta","Tal Schuster","William W Cohen","Donald Metzler"],"categories":null,"content":"","date":1657843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657843200,"objectID":"4f82083baf22f774583b95dd4a2f05f8","permalink":"https://talschuster.github.io/publication/dsi/","publishdate":"2022-07-15T00:00:00Z","relpermalink":"/publication/dsi/","section":"publication","summary":"In this paper, we demonstrate that information retrieval can be accomplished with a single Transformer, in which all information about the corpus is encoded in the parameters of the model. To this end, we introduce the Differentiable Search Index (DSI), a new paradigm that learns a text-to-text model that maps string queries directly to relevant docids; in other words, a DSI model answers queries directly using only its parameters, dramatically simplifying the whole retrieval process. We study variations in how documents and their identifiers are represented, variations in training procedures, and the interplay between models and corpus sizes. Experiments demonstrate that given appropriate design choices, DSI significantly outperforms strong baselines such as dual encoder models. Moreover, DSI demonstrates strong generalization capabilities, outperforming a BM25 baseline in a zero-shot setup.","tags":[""],"title":"Transformer Memory as a Differentiable Search Index","type":"publication"},{"authors":["Tal Schuster","Sihao Chen","Senaka Buthpitiya","Alex Fabrikant","Donald Metzler"],"categories":null,"content":"","date":1654041600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654041600,"objectID":"1722970eb58a430f9edd713c7357b1f7","permalink":"https://talschuster.github.io/publication/stretching_nli/","publishdate":"2022-06-01T00:00:00Z","relpermalink":"/publication/stretching_nli/","section":"publication","summary":"Natural Language Inference (NLI) has been extensively studied by the NLP community as a framework for estimating the semantic relation between sentence pairs. While early work identified certain biases in NLI models, recent advancements in modeling and datasets demonstrated promising performance. In this work, we further explore the direct zero-shot applicability of NLI models to real applications, beyond the sentence-pair setting they were trained on. First, we analyze the robustness of these models to longer and out-of-domain inputs. Then, we develop new aggregation methods to allow operating over full documents, reaching state-of-the-art performance on the ContractNLI dataset. Interestingly, we find NLI scores to provide strong retrieval signals, leading to more relevant evidence extractions compared to common similarity-based methods. Finally, we go further and investigate whole document clusters to identify both discrepancies and consensus among sources. In a test case, we find real inconsistencies between Wikipedia pages in different languages about the same topic.","tags":[""],"title":"Stretching Sentence-pair NLI Models to Reason over Long Documents and Clusters","type":"publication"},{"authors":["Jannis Bulian","Christian Buck","Wojciech Gajewski","Benjamin Boerschinger","Tal Schuster"],"categories":null,"content":"","date":1651363200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651363200,"objectID":"4d9cf4c1f6a5cd32a0068b5355d39718","permalink":"https://talschuster.github.io/publication/tomayto_tomahto/","publishdate":"2022-05-01T00:00:00Z","relpermalink":"/publication/tomayto_tomahto/","section":"publication","summary":"The predictions of question answering (QA) systems are typically evaluated against manually annotated finite sets of one or more answers. This leads to a coverage limitation that results in underestimating the true performance of systems, and is typically addressed by extending over exact match (EM) with predefined rules or with the token-level F1 measure. In this paper, we present the first systematic conceptual and data-driven analysis to examine the shortcomings of token-level equivalence measures. To this end, we define the asymmetric notion of answer equivalence (AE), accepting answers that are equivalent to or improve over the reference, and collect over 26K human judgements for candidates produced by multiple QA systems on SQuAD. Through a careful analysis of this data, we reveal and quantify several concrete limitations of the F1 measure, such as false impression of graduality, missing dependence on question, and more. Since collecting AE annotations for each evaluated model is expensive, we learn a BERT matching BEM measure to approximate this task. Being a simpler task than QA, we find BEM to provide significantly better AE approximations than F1, and more accurately reflect the performance of systems. Finally, we also demonstrate the practical utility of AE and BEM on the concrete application of minimal accurate prediction sets, reducing the number of required answers by up to 2.6 times.","tags":[""],"title":"Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question Answering Evaluation","type":"publication"},{"authors":["Adam Fisch","Tal Schuster","Tommi Jaakkola","Regina Barzilay"],"categories":null,"content":"","date":1644883200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1644883200,"objectID":"fa4161816c2aed24d456261f203234e5","permalink":"https://talschuster.github.io/publication/conformal_fp/","publishdate":"2022-02-15T00:00:00Z","relpermalink":"/publication/conformal_fp/","section":"publication","summary":"We develop a new approach to multi-label conformal prediction in which we aim to output a precise set of promising prediction candidates with a bounded number of incorrect answers. Standard conformal prediction provides the ability to adapt to model uncertainty by constructing a calibrated candidate set in place of a single prediction, with guarantees that the set contains the correct answer with high probability. In order to obey this coverage property, however, conformal sets can become inundated with noisy candidates—which can render them unhelpful in practice. This is particularly relevant to practical applications where there is a limited budget, and the cost (monetary or otherwise) associated with false positives is non-negligible. We propose to trade coverage for a notion of precision by enforcing that the presence of incorrect candidates in the predicted conformal sets (i.e., the total number of false positives) is bounded according to a user-specified tolerance. Subject to this constraint, our algorithm then optimizes for a generalized notion of set coverage (i.e., the true positive rate) that allows for any number of true answers for a given query (including zero). We demonstrate the effectiveness of this approach across a number of classification tasks in natural language processing, computer vision, and computational chemistry.","tags":[""],"title":"Conformal Prediction Sets with Limited False Positives","type":"publication"},{"authors":["Vamsi Aribandi","Yi Tay","Tal Schuster","Jinfeng Rao","Huaixiu Steven Zheng","Sanket Vaibhav Mehta","Honglei Zhuang","Vinh Q Tran","Dara Bahri","Jianmo Ni","Jai Gupta","Kai Hui","Sebastian Ruder","Donald Metzler"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"242c2ba54b0ccb5774e864d329d08ede","permalink":"https://talschuster.github.io/publication/ext5/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/ext5/","section":"publication","summary":"Despite the recent success of multi-task learning and transfer learning for natural language processing (NLP), few works have systematically studied the effect of scaling up the number of tasks during pre-training. Towards this goal, this paper introduces ExMix (Extreme Mixture): a massive collection of 107 supervised NLP tasks across diverse domains and task-families. Using ExMix, we study the effect of multi-task pre-training at the largest scale to date, and analyze co-training transfer amongst common families of tasks. Through this analysis, we show that manually curating an ideal set of tasks for multi-task pre-training is not straightforward, and that multi-task scaling can vastly improve models on its own. Finally, we propose ExT5: a model pre-trained using a multi-task objective of self-supervised span denoising and supervised ExMix. Via extensive experiments, we show that ExT5 outperforms strong T5 baselines on SuperGLUE, GEM, Rainbow, Closed-Book QA tasks, and several tasks outside of ExMix. ExT5 also significantly improves sample efficiency while pre-training.","tags":[""],"title":"ExT5: Towards Extreme Multi-Task Scaling for Transfer Learning","type":"publication"},{"authors":["Adam Fisch","Robin Jia","Tal Schuster"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"9d5bf387a8e163407ab0e85bfdeeb4fe","permalink":"https://talschuster.github.io/publication/uncertainty_tutorial_coling22/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/uncertainty_tutorial_coling22/","section":"publication","summary":" Accurate estimates of uncertainty are important for many difficult or sensitive prediction tasks in natural language processing (NLP). Though large-scale pre-trained models have vastly improved the accuracy of applied machine learning models throughout the field, there still are many instances in which they fail. The ability to precisely quantify uncertainty while handling the challenging scenarios that modern models can face when deployed in the real world is critical for reliable, consequential-decision making. This tutorial is intended for both academic researchers and industry practitioners alike, and provides a comprehensive introduction to uncertainty estimation for NLP problems---from fundamentals in probability calibration, Bayesian inference, and confidence set (or interval) construction, to applied topics in modern out-of-distribution detection and selective inference.","tags":[""],"title":"Uncertainty Estimation for Natural Language Processing (Tutorial)","type":"publication"},{"authors":["Tal Schuster"],"categories":null,"content":"","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630454400,"objectID":"422b01dbe09bdfe1673aa0f5029d9baa","permalink":"https://talschuster.github.io/publication/phd_thesis/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/publication/phd_thesis/","section":"publication","summary":"Deep learning models have recently revolutionized the online environment, opening up many exciting opportunities to improve the user experience. These models, however, also introduce new threats by possibly creating or promoting misinformation, either intentionally or deliberately by malicious users. In this thesis, we present novel methods to fight the proliferation of misinformation online. We focus on the task of automated fact verification where the veracity of a given claim is examined against external reliable sources. We analyze the desired specifications of fact verification systems and describe the need for efficiency when operating against large comprehensive free text information resources, while ensuring robustness to challenging inputs and sensitivity to modifications in the referenced evidence. Our methods are general and, as we demonstrate, improve the robustness, efficiency, and interpretability of many other models beyond fact verification. In the first part of this thesis, we focus on the robustness, sensitivity, and interpretability of sentence-pair classifiers. We present methodologies for identifying and quantifying idiosyncrasies in large curated datasets that undesirably lead models to rely on nongeneralizable statistical cues. We demonstrate how contrastive evidence pairs can alleviate this issue by enforcing models to perform sentence-pair inference. To obtain such examples automatically, we develop a novel rationale-based denoising pipeline for modifying refuting evidence to agree with a given claim. In addition, we present a semi-automated solution for creating contrastive pairs from Wikipedia revisions and share a new large dataset. In the second part, we turn to improve the inference efficiency of both the evidence retrieval and the claim classification modules, while reliably controlling their accuracy. We introduce new confidence measures and develop novel extensions to the conformal prediction framework. Our methods can dynamically allocate the required computational resources for each input to satisfy an arbitrary user-specified tolerance level. We demonstrate on multiple datasets that our well-calibrated decision rules reliably provide significant efficiency gains.","tags":[""],"title":"Robust and Efficient Deep Learning for Misinformation Prevention","type":"publication"},{"authors":["Tal Schuster","Ashwin Kalyan","Oleksandr Polozov","Adam Tauman Kalai"],"categories":null,"content":"Thanks Yannic Kilcher for covering this paper on ML news  :)\n","date":1623283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1623283200,"objectID":"3af23eae025b4325e48a394bfe11f094","permalink":"https://talschuster.github.io/publication/puzzles/","publishdate":"2021-06-10T00:00:00Z","relpermalink":"/publication/puzzles/","section":"publication","summary":"We introduce a new type of programming challenge called programming puzzles, as an objective and comprehensive evaluation of program synthesis, and release an open-source dataset of Python Programming Puzzles (P3). Each puzzle is defined by a short Python program $f$, and the goal is to find an input which makes $f$ return True. The puzzles are objective in that each one is specified entirely by the source code of its verifier $f$, so evaluating $f$ is all that is needed to test a candidate solution.  They do not require an answer key or input/output examples, nor do they depend on natural language understanding. The dataset is comprehensive in that it spans problems of a range of difficulties and domains, ranging from trivial string manipulation problems, to classic programming puzzles (e.g., Tower of Hanoi), to interview/competitive-programming problems (e.g., dynamic programming), to longstanding open problems in algorithms and mathematics (e.g., factoring). We develop baseline enumerative program synthesis, GPT-3 and Codex solvers that are capable of solving puzzles---even without access to any reference solutions---by learning from their own past solutions. Codex performs best, solving up to 18% of 397 test problems with a single try and 80% of the problems with 1,000 tries per problem. In a small user study, we find a positive correlation between puzzle-solving performance and coding experience, and between the puzzle difficulty for humans and AI solvers. Therefore, further improvements on P3 could have a significant impact on many program synthesis areas.","tags":[""],"title":"Programming Puzzles","type":"publication"},{"authors":["Tal Schuster","Adam Fisch","Tommi Jaakkola","Regina Barzilay"],"categories":null,"content":"","date":1618704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618704000,"objectID":"5378d83722c811009315e3e582d236b8","permalink":"https://talschuster.github.io/publication/cats/","publishdate":"2021-04-18T00:00:00Z","relpermalink":"/publication/cats/","section":"publication","summary":"We develop a novel approach for confidently accelerating inference in the large and expensive multilayer Transformers that are now ubiquitous in natural language processing (NLP). Amortized or approximate computational methods increase efficiency, but can come with unpredictable performance costs. In this work, we present CATs -- Confident Adaptive Transformers -- in which we simultaneously increase computational efficiency, while guaranteeing a specifiable degree of consistency with the original model with high confidence. Our method trains additional prediction heads on top of intermediate layers, and dynamically decides when to stop allocating computational effort to each input using a meta consistency classifier. To calibrate our early prediction stopping rule, we formulate a unique extension of conformal prediction. We demonstrate the effectiveness of this approach on four classification and regression tasks.","tags":[""],"title":"Consistent Accelerated Inference via Confident Adaptive Transformers","type":"publication"},{"authors":["Tal Schuster","Adam Fisch","Regina Barzilay"],"categories":null,"content":"","date":1615766400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615766400,"objectID":"41280200f3c721d6d1b58ac4f8ae68e3","permalink":"https://talschuster.github.io/publication/vitaminc/","publishdate":"2021-03-15T00:00:00Z","relpermalink":"/publication/vitaminc/","section":"publication","summary":"Typical fact verification models use retrieved written evidence to verify claims. Evidence sources, however, often change over time as more information is gathered and revised. In order to adapt, models must be sensitive to subtle differences in supporting evidence. We present VitaminC, a benchmark infused with challenging cases that require fact verification models to discern and adjust to slight factual changes. We collect over 100,000 Wikipedia revisions that modify an underlying fact, and leverage these revisions, together with additional synthetically constructed ones, to create a total of over 400,000 claim-evidence pairs. Unlike previous resources, the examples in VitaminC are contrastive, i.e., they contain evidence pairs that are nearly identical in language and content, with the exception that one supports a given claim while the other does not. We show that training using this design increases robustness -- improving accuracy by 10% on adversarial fact verification and 6% on adversarial natural language inference (NLI). Moreover, the structure of VitaminC leads us to define additional tasks for fact-checking resources: tagging relevant words in the evidence for verifying the claim, identifying factual revisions, and providing automatic edits via factually consistent text generation.","tags":[""],"title":"Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence","type":"publication"},{"authors":["Adam Fisch","Tal Schuster","Tommi Jaakkola","Regina Barzilay"],"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"a9804de45265a8256755466ea1f59388","permalink":"https://talschuster.github.io/publication/meta_conformal/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publication/meta_conformal/","section":"publication","summary":"We develop a novel approach to conformal prediction when the target task has limited data available for training. Conformal prediction identifies a small set of promising output candidates in place of a single prediction, with guarantees that the set contains the correct answer with high probability. When training data is limited, however, the predicted set can easily become unusably large. In this work, we obtain substantially tighter prediction sets while maintaining desirable marginal guarantees by casting conformal prediction as a meta-learning paradigm over exchangeable collections of auxiliary tasks. Our conformalization algorithm is simple, fast, and agnostic to the choice of underlying model, learning algorithm, or dataset. We demonstrate the effectiveness of this approach across a number of few-shot classification and regression tasks in natural language processing, computer vision, and computational chemistry for drug discovery.","tags":[""],"title":"Few-shot Conformal Prediction with Auxiliary Tasks","type":"publication"},{"authors":["Adam Fisch","Tal Schuster","Tommi Jaakkola","Regina Barzilay"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"222dcc3711fca587757e0fc167e1f7d2","permalink":"https://talschuster.github.io/publication/relaxed_cascaded_conformal_prediction/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/relaxed_cascaded_conformal_prediction/","section":"publication","summary":"In this paper, we present a novel approach for conformal prediction (CP), in which we aim to identify a set of promising prediction candidates---in place of a single prediction. This set is guaranteed to contain a correct answer with high probability, and is well-suited for many open-ended classification tasks. In the standard CP paradigm, the predicted set can often be unusably large and also costly to obtain. This is particularly pervasive in settings where the correct answer is not unique, and the number of total possible answers is high. We first expand the CP correctness criterion to allow for additional, inferred \"admissible\" answers, which can substantially reduce the size of the predicted set while still providing valid performance guarantees. Second, we amortize costs by conformalizing prediction cascades, in which we aggressively prune implausible labels early on by using progressively stronger classifiers---again, while still providing valid performance guarantees. We demonstrate the empirical effectiveness of our approach for multiple applications in natural language processing and computational chemistry for drug discovery.","tags":[""],"title":"Efficient Conformal Prediction via Cascaded Inference with Expanded Admission","type":"publication"},{"authors":["Enrico Santus","Tal Schuster","Amir M Tahmasebi","Clara Li","Adam Yala","Conor R Lanahan","Peter Prinsen","Scott F Thompson","Samuel Coons","Lance Mynderse","Regina Barzilay","Kevin Hughes"],"categories":null,"content":"","date":1601596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601596800,"objectID":"72269f8be14ec95f8cda917276a1243c","permalink":"https://talschuster.github.io/publication/medical_rules/","publishdate":"2020-10-02T00:00:00Z","relpermalink":"/publication/medical_rules/","section":"publication","summary":"We collected 501 prostate pathology reports from 6 American hospitals. Reports were split into 2,711 core segments, annotated with 20 attributes describing the histology, grade, extension, and location of tumors. The data set was split by institutions to generate a cross-institutional evaluation setting. We assessed 4 systems, namely a rule-based approach, an ML model, and 2 hybrid systems integrating the previous methods: a Rule as Feature model and a Classifier Confidence model. Several ML algorithms were tested, including logistic regression (LR), support vector machine (SVM), and eXtreme gradient boosting (XGB).","tags":[""],"title":"Exploiting Rules to Enhance Machine Learning in Extracting Information From Multi-Institutional Prostate Pathology Reports","type":"publication"},{"authors":["Beatrice Portelli","Jason Zhao","Tal Schuster","Giuseppe Serra","Enrico Santus"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"20b19a2a64702f6666ef6e7b7c2ebd27","permalink":"https://talschuster.github.io/publication/distil_evidence/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/publication/distil_evidence/","section":"publication","summary":"The alarming spread of fake news in social media, together with the impossibility of scaling manual fact verification, motivated the development of natural language processing techniques to automatically verify the veracity of claims. Most approaches perform a claim-evidence classification without providing any insights about why the claim is trustworthy or not. We propose, instead, a model-agnostic framework that consists of two modules: (1) a span extractor, which identifies the crucial information connecting claim and evidence; and (2) a classifier that combines claim, evidence, and the extracted spans to predict the veracity of the claim. We show that the spans are informative for the classifier, improving performance and robustness. Tested on several state-of-the-art models over the Fever dataset, the enhanced classifiers consistently achieve higher accuracy while also showing reduced sensitivity to artifacts in the claims.","tags":[""],"title":"Distilling the Evidence to Augment Fact Verification Models","type":"publication"},{"authors":["Tal Schuster","Roei Schuster","Darsh J Shah","Regina Barzilay"],"categories":null,"content":"Note: this article was earlier published under the name: Are We Safe Yet? The Limitations of Distributional Features for Fake News Detection\n","date":1581724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581724800,"objectID":"cc5f5afb81073fae84dc22603f195124","permalink":"https://talschuster.github.io/publication/are_we_safe/","publishdate":"2020-02-15T00:00:00Z","relpermalink":"/publication/are_we_safe/","section":"publication","summary":"Recent developments in neural language models (LMs) have raised concerns about their potential misuse for automatically spreading misinformation. In light of these concerns, several studies have proposed to detect machine-generated fake news by capturing their stylistic differences from human-written text. These approaches, broadly termed stylometry, have found success in source attribution and misinformation detection in human-written texts. However, in this work, we show that stylometry is limited against machine-generated misinformation. While humans speak differently when trying to deceive, LMs generate stylistically consistent text, regardless of underlying motive. Thus, though stylometry can successfully prevent impersonation by identifying text provenance, it fails to distinguish legitimate LM applications from those that introduce false information. We create two benchmarks demonstrating the stylistic similarity between malicious and legitimate uses of LMs, employed in auto-completion and editing-assistance settings. Our findings highlight the need for non-stylometry approaches in detecting machine-generated misinformation, and open up the discussion on the desired evaluation benchmarks.","tags":[""],"title":"The Limitations of Stylometry for Detecting Machine-Generated Fake News","type":"publication"},{"authors":["Roei Schuster","Tal Schuster","Yoav Meri","Vitaly Shmatikov"],"categories":null,"content":" ","date":1579046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579046400,"objectID":"9eaafb21ed893968079607b179d0191e","permalink":"https://talschuster.github.io/publication/emb_attack/","publishdate":"2020-01-15T00:00:00Z","relpermalink":"/publication/emb_attack/","section":"publication","summary":"Word embeddings, i.e., low-dimensional vector representations such as GloVe and SGNS, encode word \"meaning\" in the sense that distances between words' vectors correspond to their semantic proximity. This enables transfer learning of semantics for a variety of natural language processing tasks. Word embeddings are typically trained on large public corpora such as Wikipedia or Twitter. We demonstrate that an attacker who can modify the corpus on which the embedding is trained can control the \"meaning\" of new and existing words by changing their locations in the embedding space. We develop an explicit expression over corpus features that serves as a proxy for distance between words and establish a causative relationship between its values and embedding distances. We then show how to use this relationship for two adversarial objectives: (1) make a word a top-ranked neighbor of another word, and (2) move a word from one semantic cluster to another. An attack on the embedding can affect diverse downstream tasks, demonstrating for the first time the power of data poisoning in transfer learning scenarios. We use this attack to manipulate query expansion in information retrieval systems such as resume search, make certain names more or less visible to named entity recognition models, and cause new words to be translated to a particular target word regardless of the language. Finally, we show how the attacker can generate linguistically likely corpus modifications, thus fooling defenses that attempt to filter implausible sentences from the corpus using a language model.","tags":[""],"title":"Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning","type":"publication"},{"authors":["Darsh J Shah","Tal Schuster","Regina Barzilay"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"5ea625ac32fa8a1ac46d4980fe1487eb","permalink":"https://talschuster.github.io/publication/fact_generation/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/fact_generation/","section":"publication","summary":"Online encyclopediae like Wikipedia contain large amounts of text that need frequent corrections and updates. The new information may contradict existing content in encyclopediae. In this paper, we focus on rewriting such dynamically changing articles. This is a challenging constrained generation task, as the output must be consistent with the new information and fit into the rest of the existing document. To this end, we propose a two-step solution: (1) We identify and remove the contradicting components in a target text for a given claim, using a neutralizing stance model; (2) We expand the remaining text to be consistent with the given claim, using a novel two-encoder sequence-to-sequence model with copy attention. Applied to a Wikipedia fact update dataset, our method successfully generates updated sentences for new claims, achieving the highest SARI score. Furthermore, we demonstrate that generating synthetic data through such rewritten sentences can successfully augment the FEVER fact-checking training dataset, leading to a relative error reduction of 13%.","tags":[""],"title":"Automatic Fact-guided Sentence Modification","type":"publication"},{"authors":null,"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"478fb0dcfdddc34e1e4a4380dc95f197","permalink":"https://talschuster.github.io/project/conformal/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/project/conformal/","section":"project","summary":"Confidence-aware predictions","tags":["Vision","NLP","Deep Learning"],"title":"Conformal Prediction","type":"project"},{"authors":["Tal Schuster","Darsh J Shah","Yun Jie Serene Yeo","Daniel Filizzola","Enrico Santus","Regina Barzilay"],"categories":null,"content":"","date":1565740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565740800,"objectID":"6870585fdd769be814624a00c87dfb18","permalink":"https://talschuster.github.io/publication/fact_symmetric/","publishdate":"2019-08-14T00:00:00Z","relpermalink":"/publication/fact_symmetric/","section":"publication","summary":"Fact verification requires validating a claim in the context of evidence. We show, however, that in the popular FEVER dataset this might not necessarily be the case. Claim-only classifiers perform competitively with top evidence-aware models. In this paper, we investigate the cause of this phenomenon, identifying strong cues for predicting labels solely based on the claim, without considering any evidence. We create an evaluation set that avoids those idiosyncrasies. The performance of FEVER-trained models significantly drops when evaluated on this test set. Therefore, we introduce a regularization method which alleviates the effect of bias in the training data, obtaining improvements on the newly created test set. This work is a step towards a more sound evaluation of reasoning capabilities in fact verification models.","tags":[""],"title":"Towards Debiasing Fact Verification Models","type":"publication"},{"authors":["Adam Yala","Tal Schuster","Randy Miles","Regina Barzilay","Constance Lehman"],"categories":null,"content":"","date":1565049600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565049600,"objectID":"8a1f8e1a10a54491fee218ea25bc0648","permalink":"https://talschuster.github.io/publication/mammo_triage/","publishdate":"2019-08-06T00:00:00Z","relpermalink":"/publication/mammo_triage/","section":"publication","summary":"A DL model to triage a portion of mammograms as cancer free, improving performance and workflow efficiency.","tags":[""],"title":"A Deep Learning Model to Triage Screening Mammograms: A Simulation Study","type":"publication"},{"authors":["Tal Schuster","Ori Ram","Regina Barzilay","Amir Globerson"],"categories":null,"content":" ","date":1559606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559606400,"objectID":"0a9ee1095508d67446f94b46c8842cdd","permalink":"https://talschuster.github.io/publication/crosslingual_embed/","publishdate":"2019-06-04T00:00:00Z","relpermalink":"/publication/crosslingual_embed/","section":"publication","summary":"We introduce a novel method for multilingual transfer that utilizes deep contextual embeddings, pretrained in an unsupervised fashion. While contextual embeddings have been shown to yield richer representations of meaning compared to their static counterparts, aligning them poses a challenge due to their dynamic nature. To this end, we construct context-independent variants of the original monolingual spaces and utilize their mapping to derive an alignment for the context-dependent spaces. This mapping readily supports processing of a target language, improving transfer by context-aware embeddings. Our experimental results demonstrate the effectiveness of this approach for zero-shot and few-shot learning of dependency parsing. Specifically, our method consistently outperforms the previous state-of-the-art on 6 target languages, yielding an improvement of 6.8 LAS points on average.","tags":[""],"title":"Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing","type":"publication"},{"authors":["Adam Yala","Constance Lehman","Tal Schuster","Tally Portnoi","Regina Barzilay"],"categories":null,"content":"","date":1557187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557187200,"objectID":"d3c2c6a0b463ad2965d2743a2e7f43c0","permalink":"https://talschuster.github.io/publication/mammo_risk/","publishdate":"2019-05-07T00:00:00Z","relpermalink":"/publication/mammo_risk/","section":"publication","summary":"Deep learning models that use full-field mammograms yield substantially improved risk discrimination compared with the Tyrer-Cuzick (version 8) model.","tags":[""],"title":"A Deep Learning Mammography-based Model for Improved Breast Cancer Risk Prediction","type":"publication"},{"authors":["Tally Portnoi","Adam Yala","Tal Schuster","Regina Barzilay","Brian Dontchos","Leslie Lamb","Constance Lehman"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546819200,"objectID":"80a02bbc76309c194b5fe75a0fb0738c","permalink":"https://talschuster.github.io/publication/mri/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/mri/","section":"publication","summary":"Our DL model can assess the 5-year cancer risk on the basis of a breast MR image alone, and it showed improved individual risk discrimination when compared with a state-of-the-art risk assessment model. These results offer promising preliminary data regarding the potential of image-based risk assessment models to support more personalized care.","tags":[""],"title":"Deep Learning Model to Assess Cancer Risk on the Basis of a Breast MR Image Alone","type":"publication"},{"authors":["Constance Lehman","Adam Yala","Tal Schuster","Brian Dontchos","Manisha Bahl","Kyle Swanson","Regina Barzilay"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"be5b47b0cff44c75b70d2255263c14b1","permalink":"https://talschuster.github.io/publication/density/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/publication/density/","section":"publication","summary":"This DL model can be used to assess mammographic breast density at the level of an experienced mammographer.","tags":[""],"title":"Mammographic breast density assessment using deep learning: clinical implementation","type":"publication"},{"authors":null,"categories":null,"content":"Analyzing the space of word representations for multilingual applications and for better performance with less data.\n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"049a11ddb4792fa0a6e07d7ec7e9ee03","permalink":"https://talschuster.github.io/project/embeddings/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/project/embeddings/","section":"project","summary":"Dense representations of words","tags":["Embeddings","NLP","Deep Learning"],"title":"Word Embeddings","type":"project"},{"authors":["Tal Schuster","Lior Wolf","David Gadot"],"categories":null,"content":" ","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"7a4eb34ff58bbdaa22125d4bc053783e","permalink":"https://talschuster.github.io/publication/optical/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publication/optical/","section":"publication","summary":"We show that the matching problem that underlies optical flow requires multiple strategies, depending on the amount of image motion and other factors. We then study the implications of this observation on training a deep neural network for representing image patches in the context of descriptor based optical flow. We propose a metric learning method, which selects suitable negative samples based on the nature of the true match. This type of training produces a network that displays multiple strategies depending on the input and leads to state of the art results on the KITTI 2012 and KITTI 2015 optical flow benchmarks.","tags":[""],"title":"Optical Flow Requires Multiple Strategies (but only one network)","type":"publication"},{"authors":null,"categories":null,"content":"In this project, we aim to improve the automatic detection of false information. We rely on trustworthy sources and evaluate content claims them.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"6183e839850c7dcc636098d8a28bac59","permalink":"https://talschuster.github.io/project/fact_verification/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/project/fact_verification/","section":"project","summary":"Identifying false or inaccurate facts","tags":["NLP","Deep Learning"],"title":"Fact Verification","type":"project"},{"authors":null,"categories":null,"content":"Project website \nToday, the vast majority of breast cancers are diagnosed from mammograms. While radiologists are skilled in identifying suspicious areas once cancer is already visible on the image, they have limited capacity in predicting which patients are heading towards cancer diagnosis before mass is formed. Reliably identifying such patients is the crucial first step in preventing cancer development. Substantial research in medical literature confirms that certain changes in the breast tissue are early precursors of cancer development. However, patterns identified by humans are not sufficiently strong to act upon them.\nWe are aiming to automate these predictions by developing deep learning algorithms that can using longitudinal imaging data with known outcomes. By reading millions of images (orders of magnitude more than humans can read in their lifetime), machines should be able to assess the likelihood of cancer occurrence in a more accurate fashion. We are currently collecting a large corpus that will enable us to answer this question. Meanwhile, we are building algorithms that can help radiologists with their daily tasks of mammogram reading. The deep learning models we developed today can accurately predict breast density and identify with human accuracy a large fraction of safe screening mammograms.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"e2ab62a05f4c5180aabbef46764a1a03","permalink":"https://talschuster.github.io/project/mammography/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/project/mammography/","section":"project","summary":"Deep learning for cancer risk prediction","tags":["Medical","Deep Learning","Vision"],"title":"Medical","type":"project"},{"authors":null,"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"f8759f2a134e7085f152c4a5b42cd32d","permalink":"https://talschuster.github.io/project/optical/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/project/optical/","section":"project","summary":"Deep metric learning","tags":["Vision","Deep Learning"],"title":"Metric Learning","type":"project"},{"authors":null,"categories":null,"content":"               ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"348109ce63001d1dc146d86ce0cd8625","permalink":"https://talschuster.github.io/photography/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/photography/","section":"","summary":"               ","tags":null,"title":"Gallery","type":""}]