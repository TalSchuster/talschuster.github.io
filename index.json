[{"authors":["admin"],"categories":null,"content":" I'm a Ph.D. student at MIT CSAIL and a member of the NLP and Learn To Cure groups. I'm fortunate to be advised by Prof. Regina Barzilay. Currently, I focus on developing ML and NLP methods to improve the robustness of models, prevent undesired outcomes, and increase their performance in challenging and realistic scenarios.  I have also worked on developing deep learning screening-based methods to improve cancer detection and risk assessment.  Before coming to MIT, I was an MSc student in the Computer Science Dep. at Tel-Aviv University, advised by Prof. Lior Wolf. ","date":1615766400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1615766400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://talschuster.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I'm a Ph.D. student at MIT CSAIL and a member of the NLP and Learn To Cure groups. I'm fortunate to be advised by Prof. Regina Barzilay. Currently, I focus on developing ML and NLP methods to improve the robustness of models, prevent undesired outcomes, and increase their performance in challenging and realistic scenarios.","tags":null,"title":"Tal Schuster","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://talschuster.github.io/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Tal Schuster","Adam Fisch","Regina Barzilay"],"categories":null,"content":"","date":1615766400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1615766400,"objectID":"41280200f3c721d6d1b58ac4f8ae68e3","permalink":"https://talschuster.github.io/publication/vitaminc/","publishdate":"2021-03-15T00:00:00Z","relpermalink":"/publication/vitaminc/","section":"publication","summary":"Typical fact verification models use retrieved written evidence to verify claims. Evidence sources, however, often change over time as more information is gathered and revised. In order to adapt, models must be sensitive to subtle differences in supporting evidence. We present VitaminC, a benchmark infused with challenging cases that require fact verification models to discern and adjust to slight factual changes. We collect over 100,000 Wikipedia revisions that modify an underlying fact, and leverage these revisions, together with additional synthetically constructed ones, to create a total of over 400,000 claim-evidence pairs. Unlike previous resources, the examples in VitaminC are contrastive, i.e., they contain evidence pairs that are nearly identical in language and content, with the exception that one supports a given claim while the other does not. We show that training using this design increases robustness -- improving accuracy by 10% on adversarial fact verification and 6% on adversarial natural language inference (NLI). Moreover, the structure of VitaminC leads us to define additional tasks for fact-checking resources: tagging relevant words in the evidence for verifying the claim, identifying factual revisions, and providing automatic edits via factually consistent text generation.","tags":[""],"title":"Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence","type":"publication"},{"authors":["Adam Fisch","Tal Schuster","Tommi Jaakkola","Regina Barzilay"],"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"a9804de45265a8256755466ea1f59388","permalink":"https://talschuster.github.io/publication/meta_conformal/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publication/meta_conformal/","section":"publication","summary":"We develop a novel approach to conformal prediction when the target task has limited data available for training. Conformal prediction identifies a small set of promising output candidates in place of a single prediction, with guarantees that the set contains the correct answer with high probability. When training data is limited, however, the predicted set can easily become unusably large. In this work, we obtain substantially tighter prediction sets while maintaining desirable marginal guarantees by casting conformal prediction as a meta-learning paradigm over exchangeable collections of auxiliary tasks. Our conformalization algorithm is simple, fast, and agnostic to the choice of underlying model, learning algorithm, or dataset. We demonstrate the effectiveness of this approach across a number of few-shot classification and regression tasks in natural language processing, computer vision, and computational chemistry for drug discovery.","tags":[""],"title":"Few-shot Conformal Prediction with Auxiliary Tasks","type":"publication"},{"authors":["Adam Fisch","Tal Schuster","Tommi Jaakkola","Regina Barzilay"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"222dcc3711fca587757e0fc167e1f7d2","permalink":"https://talschuster.github.io/publication/relaxed_cascaded_conformal_prediction/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/relaxed_cascaded_conformal_prediction/","section":"publication","summary":"In this paper, we present a novel approach for conformal prediction (CP), in which we aim to identify a set of promising prediction candidates---in place of a single prediction. This set is guaranteed to contain a correct answer with high probability, and is well-suited for many open-ended classification tasks. In the standard CP paradigm, the predicted set can often be unusably large and also costly to obtain. This is particularly pervasive in settings where the correct answer is not unique, and the number of total possible answers is high. We first expand the CP correctness criterion to allow for additional, inferred \"admissible\" answers, which can substantially reduce the size of the predicted set while still providing valid performance guarantees. Second, we amortize costs by conformalizing prediction cascades, in which we aggressively prune implausible labels early on by using progressively stronger classifiers---again, while still providing valid performance guarantees. We demonstrate the empirical effectiveness of our approach for multiple applications in natural language processing and computational chemistry for drug discovery.","tags":[""],"title":"Efficient Conformal Prediction via Cascaded Inference with Expanded Admission","type":"publication"},{"authors":["Beatrice Portelli","Jason Zhao","Tal Schuster","Giuseppe Serra","Enrico Santus"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"20b19a2a64702f6666ef6e7b7c2ebd27","permalink":"https://talschuster.github.io/publication/distil_evidence/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/publication/distil_evidence/","section":"publication","summary":"The alarming spread of fake news in social media, together with the impossibility of scaling manual fact verification, motivated the development of natural language processing techniques to automatically verify the veracity of claims. Most approaches perform a claim-evidence classification without providing any insights about why the claim is trustworthy or not. We propose, instead, a model-agnostic framework that consists of two modules: (1) a span extractor, which identifies the crucial information connecting claim and evidence; and (2) a classifier that combines claim, evidence, and the extracted spans to predict the veracity of the claim. We show that the spans are informative for the classifier, improving performance and robustness. Tested on several state-of-the-art models over the Fever dataset, the enhanced classifiers consistently achieve higher accuracy while also showing reduced sensitivity to artifacts in the claims.","tags":[""],"title":"Distilling the Evidence to Augment Fact Verification Models","type":"publication"},{"authors":["Tal Schuster","Roei Schuster","Darsh J Shah","Regina Barzilay"],"categories":null,"content":"Note: this article was earlier published under the name: Are We Safe Yet? The Limitations of Distributional Features for Fake News Detection\n","date":1581724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581724800,"objectID":"cc5f5afb81073fae84dc22603f195124","permalink":"https://talschuster.github.io/publication/are_we_safe/","publishdate":"2020-02-15T00:00:00Z","relpermalink":"/publication/are_we_safe/","section":"publication","summary":"Recent developments in neural language models (LMs) have raised concerns about their potential misuse for automatically spreading misinformation. In light of these concerns, several studies have proposed to detect machine-generated fake news by capturing their stylistic differences from human-written text. These approaches, broadly termed stylometry, have found success in source attribution and misinformation detection in human-written texts. However, in this work, we show that stylometry is limited against machine-generated misinformation. While humans speak differently when trying to deceive, LMs generate stylistically consistent text, regardless of underlying motive. Thus, though stylometry can successfully prevent impersonation by identifying text provenance, it fails to distinguish legitimate LM applications from those that introduce false information. We create two benchmarks demonstrating the stylistic similarity between malicious and legitimate uses of LMs, employed in auto-completion and editing-assistance settings. Our findings highlight the need for non-stylometry approaches in detecting machine-generated misinformation, and open up the discussion on the desired evaluation benchmarks.","tags":[""],"title":"The Limitations of Stylometry for Detecting Machine-Generated Fake News","type":"publication"},{"authors":["Roei Schuster","Tal Schuster","Yoav Meri","Vitaly Shmatikov"],"categories":null,"content":" ","date":1579046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579046400,"objectID":"9eaafb21ed893968079607b179d0191e","permalink":"https://talschuster.github.io/publication/emb_attack/","publishdate":"2020-01-15T00:00:00Z","relpermalink":"/publication/emb_attack/","section":"publication","summary":"Word embeddings, i.e., low-dimensional vector representations such as GloVe and SGNS, encode word \"meaning\" in the sense that distances between words' vectors correspond to their semantic proximity. This enables transfer learning of semantics for a variety of natural language processing tasks. Word embeddings are typically trained on large public corpora such as Wikipedia or Twitter. We demonstrate that an attacker who can modify the corpus on which the embedding is trained can control the \"meaning\" of new and existing words by changing their locations in the embedding space. We develop an explicit expression over corpus features that serves as a proxy for distance between words and establish a causative relationship between its values and embedding distances. We then show how to use this relationship for two adversarial objectives: (1) make a word a top-ranked neighbor of another word, and (2) move a word from one semantic cluster to another. An attack on the embedding can affect diverse downstream tasks, demonstrating for the first time the power of data poisoning in transfer learning scenarios. We use this attack to manipulate query expansion in information retrieval systems such as resume search, make certain names more or less visible to named entity recognition models, and cause new words to be translated to a particular target word regardless of the language. Finally, we show how the attacker can generate linguistically likely corpus modifications, thus fooling defenses that attempt to filter implausible sentences from the corpus using a language model.","tags":[""],"title":"Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning","type":"publication"},{"authors":null,"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"478fb0dcfdddc34e1e4a4380dc95f197","permalink":"https://talschuster.github.io/project/conformal/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/project/conformal/","section":"project","summary":"Predicting with confidence estimates","tags":["Vision","NLP","Deep Learning"],"title":"Conformal Prediction","type":"project"},{"authors":["Darsh J Shah","Tal Schuster","Regina Barzilay"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"5ea625ac32fa8a1ac46d4980fe1487eb","permalink":"https://talschuster.github.io/publication/fact_generation/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/fact_generation/","section":"publication","summary":"Online encyclopediae like Wikipedia contain large amounts of text that need frequent corrections and updates. The new information may contradict existing content in encyclopediae. In this paper, we focus on rewriting such dynamically changing articles. This is a challenging constrained generation task, as the output must be consistent with the new information and fit into the rest of the existing document. To this end, we propose a two-step solution: (1) We identify and remove the contradicting components in a target text for a given claim, using a neutralizing stance model; (2) We expand the remaining text to be consistent with the given claim, using a novel two-encoder sequence-to-sequence model with copy attention. Applied to a Wikipedia fact update dataset, our method successfully generates updated sentences for new claims, achieving the highest SARI score. Furthermore, we demonstrate that generating synthetic data through such rewritten sentences can successfully augment the FEVER fact-checking training dataset, leading to a relative error reduction of 13%.","tags":[""],"title":"Automatic Fact-guided Sentence Modification","type":"publication"},{"authors":["Tal Schuster","Darsh J Shah","Yun Jie Serene Yeo","Daniel Filizzola","Enrico Santus","Regina Barzilay"],"categories":null,"content":"","date":1565740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565740800,"objectID":"6870585fdd769be814624a00c87dfb18","permalink":"https://talschuster.github.io/publication/fact_symmetric/","publishdate":"2019-08-14T00:00:00Z","relpermalink":"/publication/fact_symmetric/","section":"publication","summary":"Fact verification requires validating a claim in the context of evidence. We show, however, that in the popular FEVER dataset this might not necessarily be the case. Claim-only classifiers perform competitively with top evidence-aware models. In this paper, we investigate the cause of this phenomenon, identifying strong cues for predicting labels solely based on the claim, without considering any evidence. We create an evaluation set that avoids those idiosyncrasies. The performance of FEVER-trained models significantly drops when evaluated on this test set. Therefore, we introduce a regularization method which alleviates the effect of bias in the training data, obtaining improvements on the newly created test set. This work is a step towards a more sound evaluation of reasoning capabilities in fact verification models.","tags":[""],"title":"Towards Debiasing Fact Verification Models","type":"publication"},{"authors":["Adam Yala","Tal Schuster","Randy Miles","Regina Barzilay","Constance Lehman"],"categories":null,"content":"","date":1565049600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565049600,"objectID":"8a1f8e1a10a54491fee218ea25bc0648","permalink":"https://talschuster.github.io/publication/mammo_triage/","publishdate":"2019-08-06T00:00:00Z","relpermalink":"/publication/mammo_triage/","section":"publication","summary":"A DL model to triage a portion of mammograms as cancer free, improving performance and workflow efficiency.","tags":[""],"title":"A Deep Learning Model to Triage Screening Mammograms: A Simulation Study","type":"publication"},{"authors":["Tal Schuster","Ori Ram","Regina Barzilay","Amir Globerson"],"categories":null,"content":" ","date":1559606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559606400,"objectID":"b789082fe47680b66c480a0fe4fff944","permalink":"https://talschuster.github.io/publication/crosslingual_elmo/","publishdate":"2019-06-04T00:00:00Z","relpermalink":"/publication/crosslingual_elmo/","section":"publication","summary":"We introduce a novel method for multilingual transfer that utilizes deep contextual embeddings, pretrained in an unsupervised fashion. While contextual embeddings have been shown to yield richer representations of meaning compared to their static counterparts, aligning them poses a challenge due to their dynamic nature. To this end, we construct context-independent variants of the original monolingual spaces and utilize their mapping to derive an alignment for the context-dependent spaces. This mapping readily supports processing of a target language, improving transfer by context-aware embeddings. Our experimental results demonstrate the effectiveness of this approach for zero-shot and few-shot learning of dependency parsing. Specifically, our method consistently outperforms the previous state-of-the-art on 6 target languages, yielding an improvement of 6.8 LAS points on average.","tags":[""],"title":"Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing","type":"publication"},{"authors":["Adam Yala","Constance Lehman","Tal Schuster","Tally Portnoi","Regina Barzilay"],"categories":null,"content":"","date":1557187200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557187200,"objectID":"d3c2c6a0b463ad2965d2743a2e7f43c0","permalink":"https://talschuster.github.io/publication/mammo_risk/","publishdate":"2019-05-07T00:00:00Z","relpermalink":"/publication/mammo_risk/","section":"publication","summary":"Deep learning models that use full-field mammograms yield substantially improved risk discrimination compared with the Tyrer-Cuzick (version 8) model.","tags":[""],"title":"A Deep Learning Mammography-based Model for Improved Breast Cancer Risk Prediction","type":"publication"},{"authors":["Tally Portnoi","Adam Yala","Tal Schuster","Regina Barzilay","Brian Dontchos","Leslie Lamb","Constance Lehman"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546819200,"objectID":"80a02bbc76309c194b5fe75a0fb0738c","permalink":"https://talschuster.github.io/publication/mri/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/publication/mri/","section":"publication","summary":"Our DL model can assess the 5-year cancer risk on the basis of a breast MR image alone, and it showed improved individual risk discrimination when compared with a state-of-the-art risk assessment model. These results offer promising preliminary data regarding the potential of image-based risk assessment models to support more personalized care.","tags":[""],"title":"Deep Learning Model to Assess Cancer Risk on the Basis of a Breast MR Image Alone","type":"publication"},{"authors":["Constance Lehman","Adam Yala","Tal Schuster","Brian Dontchos","Manisha Bahl","Kyle Swanson","Regina Barzilay"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"be5b47b0cff44c75b70d2255263c14b1","permalink":"https://talschuster.github.io/publication/density/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/publication/density/","section":"publication","summary":"This DL model can be used to assess mammographic breast density at the level of an experienced mammographer.","tags":[""],"title":"Mammographic breast density assessment using deep learning: clinical implementation","type":"publication"},{"authors":null,"categories":null,"content":"Analyzing the space of word representations for multilingual applications and for better performance with less data.\n","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"049a11ddb4792fa0a6e07d7ec7e9ee03","permalink":"https://talschuster.github.io/project/embeddings/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/project/embeddings/","section":"project","summary":"Dense representations of words","tags":["Embeddings","NLP","Deep Learning"],"title":"Word Embeddings","type":"project"},{"authors":["Tal Schuster","Lior Wolf","David Gadot"],"categories":null,"content":" ","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"7a4eb34ff58bbdaa22125d4bc053783e","permalink":"https://talschuster.github.io/publication/optical/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publication/optical/","section":"publication","summary":"We show that the matching problem that underlies optical flow requires multiple strategies, depending on the amount of image motion and other factors. We then study the implications of this observation on training a deep neural network for representing image patches in the context of descriptor based optical flow. We propose a metric learning method, which selects suitable negative samples based on the nature of the true match. This type of training produces a network that displays multiple strategies depending on the input and leads to state of the art results on the KITTI 2012 and KITTI 2015 optical flow benchmarks.","tags":[""],"title":"Optical Flow Requires Multiple Strategies (but only one network)","type":"publication"},{"authors":null,"categories":null,"content":"In this project, we aim to improve the automatic detection of false information. We rely on trustworthy sources and evaluate content claims them.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"eb1cc1774bf3ea9730216362010aab1c","permalink":"https://talschuster.github.io/project/fake_news/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/project/fake_news/","section":"project","summary":"Misinformation detection","tags":["NLP","Deep Learning"],"title":"Fake News","type":"project"},{"authors":null,"categories":null,"content":"Project website \nToday, the vast majority of breast cancers are diagnosed from mammograms. While radiologists are skilled in identifying suspicious areas once cancer is already visible on the image, they have limited capacity in predicting which patients are heading towards cancer diagnosis before mass is formed. Reliably identifying such patients is the crucial first step in preventing cancer development. Substantial research in medical literature confirms that certain changes in the breast tissue are early precursors of cancer development. However, patterns identified by humans are not sufficiently strong to act upon them.\nWe are aiming to automate these predictions by developing deep learning algorithms that can using longitudinal imaging data with known outcomes. By reading millions of images (orders of magnitude more than humans can read in their lifetime), machines should be able to assess the likelihood of cancer occurrence in a more accurate fashion. We are currently collecting a large corpus that will enable us to answer this question. Meanwhile, we are building algorithms that can help radiologists with their daily tasks of mammogram reading. The deep learning models we developed today can accurately predict breast density and identify with human accuracy a large fraction of safe screening mammograms.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"e2ab62a05f4c5180aabbef46764a1a03","permalink":"https://talschuster.github.io/project/mammography/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/project/mammography/","section":"project","summary":"Deep learning for cancer risk prediction","tags":["Medical","Deep Learning","Vision"],"title":"Medical","type":"project"},{"authors":null,"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"f8759f2a134e7085f152c4a5b42cd32d","permalink":"https://talschuster.github.io/project/optical/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/project/optical/","section":"project","summary":"Deep metric learning","tags":["Vision","Deep Learning"],"title":"Metric Learning","type":"project"},{"authors":null,"categories":null,"content":"               ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"348109ce63001d1dc146d86ce0cd8625","permalink":"https://talschuster.github.io/photography/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/photography/","section":"","summary":"               ","tags":null,"title":"Gallery","type":""}]