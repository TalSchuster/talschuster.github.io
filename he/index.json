[{"authors":["admin"],"categories":null,"content":"אני מועמד לדוקטורט במעבדת הבינה המלאכותית של המכון הטכנולוגי של מסצ׳וסטס תחת הנחייתה של פרופ׳ רגינה ברזילי\n","date":1593907200,"expirydate":-62135596800,"kind":"taxonomy","lang":"he","lastmod":1593907200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://talschuster.github.io/he/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/he/authors/admin/","section":"authors","summary":"אני מועמד לדוקטורט במעבדת הבינה המלאכותית של המכון הטכנולוגי של מסצ׳וסטס תחת הנחייתה של פרופ׳ רגינה ברזילי","tags":null,"title":"Tal Schuster","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://talschuster.github.io/he/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/he/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Adam Fisch","Tal Schuster","Tommi Jaakkola","Regina Barzilay"],"categories":null,"content":"","date":1593907200,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1593907200,"objectID":"222dcc3711fca587757e0fc167e1f7d2","permalink":"https://talschuster.github.io/he/publication/relaxed_cascaded_conformal_prediction/","publishdate":"2020-07-05T00:00:00Z","relpermalink":"/he/publication/relaxed_cascaded_conformal_prediction/","section":"publication","summary":"Providing a small set of promising candidates in place of a single prediction is well-suited for many open-ended classification tasks. Conformal Prediction (CP) is a technique for creating classifiers that produce a valid set of predictions that contains the true answer with arbitrarily high probability. In practice, however, standard CP can suffer from both low predictive and computational efficiency during inference---i.e., the predicted set is both unusably large, and costly to obtain. This is particularly pervasive in the considered setting, where the correct answer is not unique and the number of total possible answers is high. In this work, we develop two simple and complementary techniques for improving both types of efficiencies. First, we relax CP validity to arbitrary criterions of success---allowing our framework to make more efficient predictions while remaining \"equivalently correct.\" Second, we amortize cost by conformalizing prediction cascades, in which we aggressively prune implausible labels early on by using progressively stronger classifiers---while still guaranteeing marginal coverage. We demonstrate the empirical effectiveness of our approach for multiple applications in natural language processing and computational chemistry for drug discovery.","tags":[""],"title":"Relaxed Conformal Prediction Cascades for Efficient Inference Over Many Labels","type":"publication"},{"authors":["Beatrice Portelli","Jason Zhao","Tal Schuster","Giuseppe Serra","Enrico Santus"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1593561600,"objectID":"20b19a2a64702f6666ef6e7b7c2ebd27","permalink":"https://talschuster.github.io/he/publication/distil_evidence/","publishdate":"2020-07-01T00:00:00Z","relpermalink":"/he/publication/distil_evidence/","section":"publication","summary":"The alarming spread of fake news in social media, together with the impossibility of scaling manual fact verification, motivated the development of natural language processing techniques to automatically verify the veracity of claims. Most approaches perform a claim-evidence classification without providing any insights about why the claim is trustworthy or not. We propose, instead, a model-agnostic framework that consists of two modules: (1) a span extractor, which identifies the crucial information connecting claim and evidence; and (2) a classifier that combines claim, evidence, and the extracted spans to predict the veracity of the claim. We show that the spans are informative for the classifier, improving performance and robustness. Tested on several state-of-the-art models over the Fever dataset, the enhanced classifiers consistently achieve higher accuracy while also showing reduced sensitivity to artifacts in the claims.","tags":[""],"title":"Distilling the Evidence to Augment Fact Verification Models","type":"publication"},{"authors":["Tal Schuster","Roei Schuster","Darsh J Shah","Regina Barzilay"],"categories":null,"content":"Note: this article was earlier published under the name: Are We Safe Yet? The Limitations of Distributional Features for Fake News Detection\n","date":1581724800,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1581724800,"objectID":"cc5f5afb81073fae84dc22603f195124","permalink":"https://talschuster.github.io/he/publication/are_we_safe/","publishdate":"2020-02-15T00:00:00Z","relpermalink":"/he/publication/are_we_safe/","section":"publication","summary":"Recent developments in neural language models (LMs) have raised concerns about their potential misuse for automatically spreading misinformation. In light of these concerns, several studies have proposed to detect machine-generated fake news by capturing their stylistic differences from human-written text. These approaches, broadly termed stylometry, have found success in source attribution and misinformation detection in human-written texts. However, in this work, we show that stylometry is limited against machine-generated misinformation. While humans speak differently when trying to deceive, LMs generate stylistically consistent text, regardless of underlying motive. Thus, though stylometry can successfully prevent impersonation by identifying text provenance, it fails to distinguish legitimate LM applications from those that introduce false information. We create two benchmarks demonstrating the stylistic similarity between malicious and legitimate uses of LMs, employed in auto-completion and editing-assistance settings. Our findings highlight the need for non-stylometry approaches in detecting machine-generated misinformation, and open up the discussion on the desired evaluation benchmarks.","tags":[""],"title":"The Limitations of Stylometry for Detecting Machine-Generated Fake News","type":"publication"},{"authors":["Roei Schuster","Tal Schuster","Yoav Meri","Vitaly Shmatikov"],"categories":null,"content":" ","date":1579046400,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1579046400,"objectID":"9eaafb21ed893968079607b179d0191e","permalink":"https://talschuster.github.io/he/publication/emb_attack/","publishdate":"2020-01-15T00:00:00Z","relpermalink":"/he/publication/emb_attack/","section":"publication","summary":"Word embeddings, i.e., low-dimensional vector representations such as GloVe and SGNS, encode word \"meaning\" in the sense that distances between words' vectors correspond to their semantic proximity. This enables transfer learning of semantics for a variety of natural language processing tasks. Word embeddings are typically trained on large public corpora such as Wikipedia or Twitter. We demonstrate that an attacker who can modify the corpus on which the embedding is trained can control the \"meaning\" of new and existing words by changing their locations in the embedding space. We develop an explicit expression over corpus features that serves as a proxy for distance between words and establish a causative relationship between its values and embedding distances. We then show how to use this relationship for two adversarial objectives: (1) make a word a top-ranked neighbor of another word, and (2) move a word from one semantic cluster to another. An attack on the embedding can affect diverse downstream tasks, demonstrating for the first time the power of data poisoning in transfer learning scenarios. We use this attack to manipulate query expansion in information retrieval systems such as resume search, make certain names more or less visible to named entity recognition models, and cause new words to be translated to a particular target word regardless of the language. Finally, we show how the attacker can generate linguistically likely corpus modifications, thus fooling defenses that attempt to filter implausible sentences from the corpus using a language model.","tags":[""],"title":"Humpty Dumpty: Controlling Word Meanings via Corpus Poisoning","type":"publication"},{"authors":["Darsh J Shah","Tal Schuster","Regina Barzilay"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1569888000,"objectID":"5ea625ac32fa8a1ac46d4980fe1487eb","permalink":"https://talschuster.github.io/he/publication/fact_generation/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/he/publication/fact_generation/","section":"publication","summary":"Online encyclopediae like Wikipedia contain large amounts of text that need frequent corrections and updates. The new information may contradict existing content in encyclopediae. In this paper, we focus on rewriting such dynamically changing articles. This is a challenging constrained generation task, as the output must be consistent with the new information and fit into the rest of the existing document. To this end, we propose a two-step solution: (1) We identify and remove the contradicting components in a target text for a given claim, using a neutralizing stance model; (2) We expand the remaining text to be consistent with the given claim, using a novel two-encoder sequence-to-sequence model with copy attention. Applied to a Wikipedia fact update dataset, our method successfully generates updated sentences for new claims, achieving the highest SARI score. Furthermore, we demonstrate that generating synthetic data through such rewritten sentences can successfully augment the FEVER fact-checking training dataset, leading to a relative error reduction of 13%.","tags":[""],"title":"Automatic Fact-guided Sentence Modification","type":"publication"},{"authors":["Tal Schuster","Darsh J Shah","Yun Jie Serene Yeo","Daniel Filizzola","Enrico Santus","Regina Barzilay"],"categories":null,"content":"","date":1565740800,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1565740800,"objectID":"6870585fdd769be814624a00c87dfb18","permalink":"https://talschuster.github.io/he/publication/fact_symmetric/","publishdate":"2019-08-14T00:00:00Z","relpermalink":"/he/publication/fact_symmetric/","section":"publication","summary":"Fact verification requires validating a claim in the context of evidence. We show, however, that in the popular FEVER dataset this might not necessarily be the case. Claim-only classifiers perform competitively with top evidence-aware models. In this paper, we investigate the cause of this phenomenon, identifying strong cues for predicting labels solely based on the claim, without considering any evidence. We create an evaluation set that avoids those idiosyncrasies. The performance of FEVER-trained models significantly drops when evaluated on this test set. Therefore, we introduce a regularization method which alleviates the effect of bias in the training data, obtaining improvements on the newly created test set. This work is a step towards a more sound evaluation of reasoning capabilities in fact verification models.","tags":[""],"title":"Towards Debiasing Fact Verification Models","type":"publication"},{"authors":["Adam Yala","Tal Schuster","Randy Miles","Regina Barzilay","Constance Lehman"],"categories":null,"content":"","date":1565049600,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1565049600,"objectID":"8a1f8e1a10a54491fee218ea25bc0648","permalink":"https://talschuster.github.io/he/publication/mammo_triage/","publishdate":"2019-08-06T00:00:00Z","relpermalink":"/he/publication/mammo_triage/","section":"publication","summary":"A DL model to triage a portion of mammograms as cancer free, improving performance and workflow efficiency.","tags":[""],"title":"A Deep Learning Model to Triage Screening Mammograms: A Simulation Study","type":"publication"},{"authors":["Tal Schuster","Ori Ram","Regina Barzilay","Amir Globerson"],"categories":null,"content":" ","date":1559606400,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1559606400,"objectID":"b789082fe47680b66c480a0fe4fff944","permalink":"https://talschuster.github.io/he/publication/crosslingual_elmo/","publishdate":"2019-06-04T00:00:00Z","relpermalink":"/he/publication/crosslingual_elmo/","section":"publication","summary":"We introduce a novel method for multilingual transfer that utilizes deep contextual embeddings, pretrained in an unsupervised fashion. While contextual embeddings have been shown to yield richer representations of meaning compared to their static counterparts, aligning them poses a challenge due to their dynamic nature. To this end, we construct context-independent variants of the original monolingual spaces and utilize their mapping to derive an alignment for the context-dependent spaces. This mapping readily supports processing of a target language, improving transfer by context-aware embeddings. Our experimental results demonstrate the effectiveness of this approach for zero-shot and few-shot learning of dependency parsing. Specifically, our method consistently outperforms the previous state-of-the-art on 6 target languages, yielding an improvement of 6.8 LAS points on average.","tags":[""],"title":"Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing","type":"publication"},{"authors":["Adam Yala","Constance Lehman","Tal Schuster","Tally Portnoi","Regina Barzilay"],"categories":null,"content":"","date":1557187200,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1557187200,"objectID":"d3c2c6a0b463ad2965d2743a2e7f43c0","permalink":"https://talschuster.github.io/he/publication/mammo_risk/","publishdate":"2019-05-07T00:00:00Z","relpermalink":"/he/publication/mammo_risk/","section":"publication","summary":"Deep learning models that use full-field mammograms yield substantially improved risk discrimination compared with the Tyrer-Cuzick (version 8) model.","tags":[""],"title":"A Deep Learning Mammography-based Model for Improved Breast Cancer Risk Prediction","type":"publication"},{"authors":["Tally Portnoi","Adam Yala","Tal Schuster","Regina Barzilay","Brian Dontchos","Leslie Lamb","Constance Lehman"],"categories":null,"content":"","date":1546819200,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1546819200,"objectID":"80a02bbc76309c194b5fe75a0fb0738c","permalink":"https://talschuster.github.io/he/publication/mri/","publishdate":"2019-01-07T00:00:00Z","relpermalink":"/he/publication/mri/","section":"publication","summary":"Our DL model can assess the 5-year cancer risk on the basis of a breast MR image alone, and it showed improved individual risk discrimination when compared with a state-of-the-art risk assessment model. These results offer promising preliminary data regarding the potential of image-based risk assessment models to support more personalized care.","tags":[""],"title":"Deep Learning Model to Assess Cancer Risk on the Basis of a Breast MR Image Alone","type":"publication"},{"authors":["Constance Lehman","Adam Yala","Tal Schuster","Brian Dontchos","Manisha Bahl","Kyle Swanson","Regina Barzilay"],"categories":null,"content":"","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1538352000,"objectID":"be5b47b0cff44c75b70d2255263c14b1","permalink":"https://talschuster.github.io/he/publication/density/","publishdate":"2018-10-01T00:00:00Z","relpermalink":"/he/publication/density/","section":"publication","summary":"This DL model can be used to assess mammographic breast density at the level of an experienced mammographer.","tags":[""],"title":"Mammographic breast density assessment using deep learning: clinical implementation","type":"publication"},{"authors":["Tal Schuster","Lior Wolf","David Gadot"],"categories":null,"content":" ","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1498867200,"objectID":"7a4eb34ff58bbdaa22125d4bc053783e","permalink":"https://talschuster.github.io/he/publication/optical/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/he/publication/optical/","section":"publication","summary":"We show that the matching problem that underlies optical flow requires multiple strategies, depending on the amount of image motion and other factors. We then study the implications of this observation on training a deep neural network for representing image patches in the context of descriptor based optical flow. We propose a metric learning method, which selects suitable negative samples based on the nature of the true match. This type of training produces a network that displays multiple strategies depending on the input and leads to state of the art results on the KITTI 2012 and KITTI 2015 optical flow benchmarks.","tags":[""],"title":"Optical Flow Requires Multiple Strategies (but only one network)","type":"publication"},{"authors":null,"categories":null,"content":"In this project, we aim to improve the automatic detection of false information. We rely on trustworthy sources and evaluate content against them.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1483228800,"objectID":"eb1cc1774bf3ea9730216362010aab1c","permalink":"https://talschuster.github.io/he/project/fake_news/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/he/project/fake_news/","section":"project","summary":"Automatic detection of false information in articles.","tags":["NLP","Deep Learning"],"title":"Fake News","type":"project"},{"authors":null,"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1483228800,"objectID":"f8759f2a134e7085f152c4a5b42cd32d","permalink":"https://talschuster.github.io/he/project/optical/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/he/project/optical/","section":"project","summary":"Sample selection when training deep learning models.","tags":["Vision","Deep Learning"],"title":"Learning Strategies","type":"project"},{"authors":null,"categories":null,"content":"Project website \nToday, the vast majority of breast cancers are diagnosed from mammograms. While radiologists are skilled in identifying suspicious areas once cancer is already visible on the image, they have limited capacity in predicting which patients are heading towards cancer diagnosis before mass is formed. Reliably identifying such patients is the crucial first step in preventing cancer development. Substantial research in medical literature confirms that certain changes in the breast tissue are early precursors of cancer development. However, patterns identified by humans are not sufficiently strong to act upon them.\nWe are aiming to automate these predictions by developing deep learning algorithms that can using longitudinal imaging data with known outcomes. By reading millions of images (orders of magnitude more than humans can read in their lifetime), machines should be able to assess the likelihood of cancer occurrence in a more accurate fashion. We are currently collecting a large corpus that will enable us to answer this question. Meanwhile, we are building algorithms that can help radiologists with their daily tasks of mammogram reading. The deep learning models we developed today can accurately predict breast density and identify with human accuracy a large fraction of safe screening mammograms.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1483228800,"objectID":"e2ab62a05f4c5180aabbef46764a1a03","permalink":"https://talschuster.github.io/he/project/mammography/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/he/project/mammography/","section":"project","summary":"Deep learning models to improve cancer risk assessment.","tags":["Medical","Deep Learning","Vision"],"title":"Medical","type":"project"},{"authors":null,"categories":null,"content":"Analyzing the space of word represenations for multilingual applications and for better performance with less data.\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":1483228800,"objectID":"049a11ddb4792fa0a6e07d7ec7e9ee03","permalink":"https://talschuster.github.io/he/project/embeddings/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/he/project/embeddings/","section":"project","summary":"Dense representations of words for NLP.","tags":["Embeddings","NLP","Deep Learning"],"title":"Word Embeddings","type":"project"},{"authors":null,"categories":null,"content":"               ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"he","lastmod":-62135596800,"objectID":"348109ce63001d1dc146d86ce0cd8625","permalink":"https://talschuster.github.io/he/photography/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/he/photography/","section":"","summary":"               ","tags":null,"title":"Gallery","type":""}]